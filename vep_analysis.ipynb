{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the montage of sensor channel locations and set up the files to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.read_montage('standard_1020')\n",
    "#edf_file = 'EEG_TEST_0001_raw.edf'\n",
    "#log_file = 'log3.csv'\n",
    "edf_file = os.path.expanduser('~/Desktop/Data/anya_inversion1_raw.edf')\n",
    "log_file = os.path.expanduser('~/Desktop/Data/anya_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(edf_file, stim_channel='Trigger', eog=['EEG X1-Pz'], \n",
    "                          misc=['EEG CM-Pz','EEG X2-Pz','EEG X3-Pz'])\n",
    "# Rename the channels so they match the standard montage channel names\n",
    "raw.rename_channels({c:c.replace('EEG ','').replace('-Pz','') for c in raw.ch_names})\n",
    "raw.set_montage(montage)\n",
    "eeg_sample_interval_ms = 1/raw.info['sfreq'] * 1000\n",
    "print(raw.info)\n",
    "#raw.plot_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdf = pd.read_csv(log_file, header=None, names=['client_ts','trigger_ts'])\n",
    "logdf = (logdf*1000).astype(int)\n",
    "logdf['bytecode'] = logdf.client_ts % 255 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimal fuzzy alignment between the log file and event bytecode sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logn = logdf.shape[0]\n",
    "eventn = events.shape[0]\n",
    "if logn > eventn:\n",
    "    shift_vals = logn - eventn\n",
    "    err = np.zeros(shift_vals)\n",
    "    for shift in range(shift_vals):\n",
    "        err[shift] = np.sqrt(((logdf.bytecode[shift:shift+eventn] - events[:,2])**2).sum())\n",
    "    shift = np.argmin(err)\n",
    "else:\n",
    "    shift = 0\n",
    "    err = np.sqrt(((logdf.bytecode[shift:shift+eventn] - events[:,2])**2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge events and log file\n",
    "Note that the sequence needs to be resorted based on the client timestamp, as logged events could come in out of order. I.e., an errant TCP packet can hit the trigger device after a subsequent packet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logdf.copy(deep=True).iloc[shift:shift+eventn,:]\n",
    "df['bytecodeEvent'] = events[:,2]\n",
    "#(df.bytecode==df.bytecodeEvent).sum()/df.shape[0]\n",
    "df['ts_event'] = events[:,0]\n",
    "df.sort_values('client_ts', inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df['delay'] = ((df.trigger_ts - df.client_ts) / eeg_sample_interval_ms).round().astype(int)\n",
    "df['ts_event_corrected'] = df.ts_event - df.delay\n",
    "\n",
    "# TODO: estimate network delay from round-trip times and use that to get an accurate client/tirgger clock bias\n",
    "clock_bias = df.delay.mean()\n",
    "print('clock_bias = %0.2fms' % clock_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize a corrected event sequence\n",
    "This new sequence takes into account the random delay from one even to the next and the average network delay. Because event trigger packets can arrive out-of-order, they needed to be resorted above to apply the proper delays. But now that everything is corrected, we can resort them based on the event timestamp so mne doesn't complain about a non-chronological event sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventdf = pd.DataFrame(columns=['ts','diff','code'])\n",
    "# clock_bias is in milliseconds-- convert to the EEG time stamps\n",
    "eventdf.ts = df.ts_event_corrected.values + int(round(clock_bias / eeg_sample_interval_ms))\n",
    "eventdf['diff'] = 0\n",
    "eventdf.code = 1\n",
    "eventdf.drop_duplicates(subset='ts', keep='first', inplace=True)\n",
    "eventdf = eventdf.sort_values('ts').reset_index(drop=True)\n",
    "#plt.plot(eventdf.ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_no_ref, _ = mne.set_eeg_reference(raw.load_data().filter(l_freq=None, h_freq=45), [])\n",
    "#raw_no_ref, _ = mne.set_eeg_reference(raw.load_data(), [])\n",
    "reject = dict(eeg=180e-6) # 180e-6, eog=150e-6)\n",
    "event_id, tmin, tmax = {'visual': 1}, -0.1, 0.5\n",
    "epochs_params = dict(events=eventdf.values, event_id=event_id, tmin=tmin, tmax=tmax, reject=reject)\n",
    "evoked_no_ref = mne.Epochs(raw_no_ref, **epochs_params).average()\n",
    "del raw_no_ref  # save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'EEG Original reference'\n",
    "evoked_no_ref.plot(titles={'eeg':'title'}, time_unit='ms')#, picks=['O1','O2','P3','P4'])\n",
    "evoked_no_ref.plot_topomap(times=[0.075,0.1,0.125,.15,.175], size=1.0, title=title, time_unit='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample code for doing frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ = raw.get_data(['O1','O2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = np.fft.rfft(occ)\n",
    "T = eeg_sample_interval_ms / 1000\n",
    "xf = np.linspace(0.0, 1.0/(2.0*T), int(np.ceil(occ.shape[1]/2))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(12,6))\n",
    "plt.plot(xf[100:15000], np.abs(ft[1,100:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.client_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
